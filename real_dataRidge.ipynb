{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\honli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\imageio\\plugins\\_tifffile.py:7285: UserWarning: module 'imageio.plugins._tifffile' has no attribute 'decode_packbits'\n",
      "  Functionality might be degraded or be slow.\n",
      "\n",
      "  warnings.warn(\"%s%s\" % (e, warn))\n",
      "C:\\Users\\honli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\imageio\\plugins\\_tifffile.py:7285: UserWarning: module 'imageio.plugins._tifffile' has no attribute 'decode_lzw'\n",
      "  Functionality might be degraded or be slow.\n",
      "\n",
      "  warnings.warn(\"%s%s\" % (e, warn))\n",
      "C:\\Users\\honli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\imageio\\plugins\\_tifffile.py:7285: UserWarning: module 'imageio.plugins._tifffile' has no attribute 'unpack_ints'\n",
      "  Functionality might be degraded or be slow.\n",
      "\n",
      "  warnings.warn(\"%s%s\" % (e, warn))\n",
      "C:\\Users\\honli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\imageio\\plugins\\_tifffile.py:7285: UserWarning: module 'imageio.plugins._tifffile' has no attribute 'reverse_bitorder'\n",
      "  Functionality might be degraded or be slow.\n",
      "\n",
      "  warnings.warn(\"%s%s\" % (e, warn))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "def surface_plot(surface,title, surface1=None):\n",
    "    M,N = surface.shape\n",
    "\n",
    "    ax_rows = np.arange(M)\n",
    "    ax_cols = np.arange(N)\n",
    "\n",
    "    [X,Y] = np.meshgrid(ax_cols, ax_rows)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    if surface1 is not None:\n",
    "        ax = fig.add_subplot(1,2,1,projection='3d')\n",
    "        ax.plot_surface(X,Y,surface,cmap=cm.viridis,linewidth=0)\n",
    "        plt.title(title)\n",
    "\n",
    "        ax = fig.add_subplot(1,2,2,projection='3d')\n",
    "        ax.plot_surface(X,Y,surface1,cmap=cm.viridis,linewidth=0)\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.plot_surface(X,Y,surface,cmap=cm.viridis,linewidth=0)\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "def predict(rows, cols, beta):\n",
    "    out = np.zeros((np.size(rows), np.size(cols)))\n",
    "\n",
    "    for i,y_ in enumerate(rows):\n",
    "        for j,x_ in enumerate(cols):\n",
    "            data_vec = np.array([1, x_, y_, x_**2, x_*y_, y_**2, \\\n",
    "                                x_**3, x_**2*y_, x_*y_**2, y_**3, \\\n",
    "                                x_**4, x_**3*y_, x_**2*y_**2, x_*y_**3,y_**4, \\\n",
    "                                x_**5, x_**4*y_, x_**3*y_**2, x_**2*y_**3,x_*y_**4,y_**5])#,\\\n",
    "            out[i,j] = data_vec @ beta\n",
    "\n",
    "    return out\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # open result files\n",
    "    text_file = open(\"real_dataRidge.txt\", \"w+\")\n",
    "    text_file.write(\"pitch; mse; R2; var; bias \\n\")\n",
    "    text_re_file = open(\"real_dataRidge_p.txt\", \"w+\")\n",
    "    text_re_file.write(\"pitch; ori; pre \\n\")\n",
    "\n",
    "    lamda = 0.01\n",
    "    # Load the terrain\n",
    "    ori_terrain = imread('SRTM_data_Norway_1.tif')\n",
    "    [n,m] = ori_terrain.shape\n",
    "\n",
    "    ## Find some random patches within the dataset and perform a fit\n",
    "\n",
    "    patch_size_row = 100\n",
    "    patch_size_col = 50\n",
    "\n",
    "    # Define their axes\n",
    "    rows = np.linspace(0,1,patch_size_row)\n",
    "    cols = np.linspace(0,1,patch_size_col)\n",
    "\n",
    "    [C,R] = np.meshgrid(cols,rows)\n",
    "\n",
    "    x = C.reshape(-1,1)\n",
    "    y = R.reshape(-1,1)\n",
    "\n",
    "    num_data = patch_size_row*patch_size_col\n",
    "\n",
    "    # Find the start indices of each patch\n",
    "\n",
    "    num_patches = 5\n",
    "\n",
    "    np.random.seed(4155)\n",
    "\n",
    "    row_starts = np.random.randint(0,n-patch_size_row,num_patches)\n",
    "    col_starts = np.random.randint(0,m-patch_size_col,num_patches)\n",
    "\n",
    "    for i,row_start, col_start in zip(np.arange(num_patches),row_starts, col_starts):\n",
    "        row_end = row_start + patch_size_row\n",
    "        col_end = col_start + patch_size_col\n",
    "\n",
    "        patch = ori_terrain[row_start:row_end, col_start:col_end]\n",
    "\n",
    "        z = patch.reshape(-1,1)\n",
    "\n",
    "        # Perform OLS fit\n",
    "        data = np.c_[np.ones((num_data,1)), x, y, \\\n",
    "                     x**2, x*y, y**2, \\\n",
    "                     x**3, x**2*y, x*y**2, y**3, \\\n",
    "                     x**4, x**3*y, x**2*y**2, x*y**3,y**4, \\\n",
    "                     x**5, x**4*y, x**3*y**2, x**2*y**3,x*y**4, y**5]#, \\\n",
    " \n",
    "        beta_ols = np.linalg.inv(data.T @ data + lamda * np.ones((data.shape[1],data.shape[1]))) @ data.T @ z   \n",
    " \n",
    "        fitted_patch = predict(rows, cols, beta_ols)\n",
    "\n",
    "        mse = np.sum( (fitted_patch - patch)**2 )/num_data\n",
    "        R2 = 1 - np.sum( (fitted_patch - patch)**2 )/np.sum( (patch - np.mean(patch))**2 )\n",
    "        var = np.sum( (fitted_patch - np.mean(fitted_patch))**2 )/num_data\n",
    "        bias = np.sum( (patch - np.mean(fitted_patch))**2 )/num_data\n",
    "\n",
    "        text_file.write(\"%d; %.4f; %.4f; %.4f; %.4f \\n\" % (i+1, mse, R2, var, bias)) \n",
    "        surface_plot(fitted_patch,'Fitted terrain surface',patch)\n",
    "        \n",
    "        \n",
    "        ori = patch.reshape(-1,1)\n",
    "        predicted = fitted_patch.reshape(-1,1)\n",
    "        for ip in range(len(ori)):\n",
    "            ori_value = ori[ip]\n",
    "            pre_value = predicted[ip]\n",
    "            text_re_file.write(\"%d; %.4f; %.4f \\n\" % (i + 1, ori_value, pre_value))\n",
    " \n",
    "        \n",
    "    # Perform fit over the whole dataset\n",
    "    print(\"The whole dataset\")\n",
    "\n",
    "    rows = np.linspace(0,1,n)\n",
    "    cols = np.linspace(0,1,m)\n",
    "\n",
    "    [C,R] = np.meshgrid(cols,rows)\n",
    "\n",
    "    x = C.reshape(-1,1)\n",
    "    y = R.reshape(-1,1)\n",
    "\n",
    "    num_data = n*m\n",
    "\n",
    "    data = np.c_[np.ones((num_data,1)), x, y, \\\n",
    "                 x**2, x*y, y**2, \\\n",
    "                 x**3, x**2*y, x*y**2, y**3, \\\n",
    "                 x**4, x**3*y, x**2*y**2, x*y**3,y**4, \\\n",
    "                 x**5, x**4*y, x**3*y**2, x**2*y**3,x*y**4, y**5]\n",
    "\n",
    "    z = ori_terrain.flatten()\n",
    "    \n",
    "    #beta_ols = np.linalg.inv(data.T @ data) @ data.T @ z\n",
    "    beta_ols = np.linalg.inv(data.T @ data + lamda * np.ones((data.shape[1],data.shape[1]))) @ data.T @ z\n",
    "    \n",
    "\n",
    "    fitted_terrain = predict(rows, cols, beta_ols)\n",
    "\n",
    "    mse = np.sum( (fitted_terrain - ori_terrain)**2 )/num_data\n",
    "    R2 = 1 - np.sum( (fitted_terrain - ori_terrain)**2 )/np.sum( (ori_terrain- np.mean(ori_terrain))**2 )\n",
    "    var = np.sum( (fitted_terrain - np.mean(fitted_terrain))**2 )/num_data\n",
    "    bias = np.sum( (ori_terrain - np.mean(fitted_terrain))**2 )/num_data\n",
    "\n",
    "    text_file.write(\"%d; %.4f; %.4f; %.4f; %.4f \\n\" % (i+1, mse, R2, var, bias))\n",
    "    text_file.close()\n",
    "    \n",
    "    ori = ori_terrain.reshape(-1,1)\n",
    "    predicted = fitted_terrain.reshape(-1,1)\n",
    "    for ip in range(len(ori)):\n",
    "        ori_value = ori[ip]\n",
    "        pre_value = predicted[ip]\n",
    "        text_re_file.write(\"%d; %.4f; %.4f \\n\" % (i + 1, ori_value, pre_value))\n",
    "        \n",
    "    text_re_file.close()\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
